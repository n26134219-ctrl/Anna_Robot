"""
å…¨å±€å…±äº«æ¨¡å‹æ¨¡çµ„ - æ‰€æœ‰ CameraDetector å¯¦ä¾‹å…±ç”¨
æ¨¡å‹åªè¼‰å…¥ä¸€æ¬¡ï¼Œç¯€çœè¨˜æ†¶é«”
"""
import torch
import os
from groundingdino.util.inference import load_model
from segment_anything import SamPredictor, sam_model_registry
from transformers import CLIPProcessor, CLIPModel
import gc
from pathlib import Path
class SharedModels:
    """å…¨å±€æ¨¡å‹å–®ä¾‹ - ç¢ºä¿æ¨¡å‹åªè¼‰å…¥ä¸€æ¬¡"""
    _instance = None
    _lock = None
    
    def __new__(cls):
        if cls._instance is None:
            import threading
            cls._lock = threading.Lock()
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰"""
        if self._initialized:
            return
        
        print("\n" + "="*60)
        print("ğŸ”„ åˆå§‹åŒ–å…¨å±€æ¨¡å‹ï¼ˆä¸€æ¬¡æ€§ï¼‰")
        print("="*60)
        
        # self.device = torch.device("cpu")
        # os.environ["FORCE_CPU"] = "1"
        self.device  = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è¨­å‚™: {self.device}")
        # print(f"cuDNN å•Ÿç”¨: {cudnn.enabled}")
        # 1ï¸âƒ£ GroundingDINO
        print("\n[1/4] è¼‰å…¥ GroundingDINO...")
        CONFIG_PATH = "/home/gairobots/camera/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
        WEIGHTS_PATH = "/home/gairobots/camera/GroundingDINO/weights/groundingdino_swint_ogc.pth"
        self.gd_model = load_model(CONFIG_PATH, WEIGHTS_PATH, device=self.device)
        print("      âœ“ GroundingDINO è¼‰å…¥å®Œæˆ")
        
        # 2ï¸âƒ£ SAM
        print("[2/4] è¼‰å…¥ SAM...")
        sam = sam_model_registry["default"](
            checkpoint="/home/gairobots/camera/GroundingDINO/sam_checkpoints/sam_vit_h_4b8939.pth"
        )
        sam.to(self.device)
        self.predictor = SamPredictor(sam)
        print("      âœ“ SAM è¼‰å…¥å®Œæˆ")
        
        # 3ï¸âƒ£ CLIP
        print("[3/4] è¼‰å…¥ CLIP...")
        self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(self.device)
        self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        print("      âœ“ CLIP è¼‰å…¥å®Œæˆ")
        
        # æ¡æŸ„ç‰¹å¾µ
        print("[4/4] è½½å…¥æ¡æŸ„ç‰¹å¾...")
        self.handle_features = {}  # å­—å…¸å­˜å‚¨
        self.load_handle_features()

        # print("[4/4] è¼‰å…¥æ¡æŸ„ç‰¹å¾µ...")
        # self.handle_reference_features = None
        # features_path = "/home/gairobots/camera/GroundingDINO/data/handle_features.pt"
        # if os.path.exists(features_path):
        #     try:
        #         self.handle_reference_features = torch.load(features_path, map_location=self.device)
        #         print(f"      âœ“ æ¡æŸ„ç‰¹å¾µå·²è¼‰å…¥ (ç¶­åº¦: {self.handle_reference_features.shape})")
        #     except Exception as e:
        #         print(f"      âš ï¸  æ¡æŸ„ç‰¹å¾µè¼‰å…¥å¤±æ•—: {e}")
        # else:
        #     print(f"      âš ï¸  æ¡æŸ„ç‰¹å¾µæª”æ¡ˆä¸å­˜åœ¨: {features_path}")
        
        self._initialized = True
        print("\n" + "="*60)
        print("âœ… å…¨å±€æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼æ‰€æœ‰ç›¸æ©Ÿå°‡å…±äº«é€™äº›æ¨¡å‹")
        print("="*60 + "\n")

    def load_handle_features(self):
        """è½½å…¥æ‰€æœ‰å·¥å…·çš„æ¡æŸ„ç‰¹å¾"""
        features_dir = Path("/home/gairobots/camera/GroundingDINO/data/handle_features")
        tool_categories = {
            'brush tool': 'brush_handle_features.pt',
            'dustpan tool': 'dustpan_handle_features.pt',
           
        }
        loaded_count = 0
        for tool_name, filename in tool_categories.items():
            feature_path = features_dir / filename
            
            if feature_path.exists():
                try:
                    features = torch.load(feature_path, map_location=self.device)
                    self.handle_features[tool_name] = features
                    loaded_count += 1
                    print(f"      âœ“ {tool_name} ç‰¹å¾å·²è½½å…¥ (ç»´åº¦: {features.shape})")
                except Exception as e:
                    print(f"      âš ï¸  {tool_name} è½½å…¥å¤±è´¥: {e}")
            else:
                print(f"      âš ï¸  æ‰¾ä¸åˆ° {tool_name} ç‰¹å¾: {feature_path}")
        
        print(f"      æ€»è®¡è½½å…¥ {loaded_count}/{len(tool_categories)} ä¸ªå·¥å…·ç‰¹å¾")
    def get_handle_features(self, tool_class):
        """è·å–ç‰¹å®šå·¥å…·çš„æŠŠæ‰‹ç‰¹å¾"""
        # ä¼˜å…ˆè¿”å›ç‰¹å®šå·¥å…·ç‰¹å¾
        if tool_class in self.handle_features:
            return self.handle_features[tool_class]
        print(f"      âš ï¸  æ— å¯ç”¨ç‰¹å¾ for {tool_class}")
        return None    
    def release(self):
        """é‡‹æ”¾æ‰€æœ‰æ¨¡å‹è³‡æºä¸¦æ¸…ç©º GPU/CPU è¨˜æ†¶é«”"""
        if not self._initialized:
            print("âš ï¸  æ¨¡å‹å°šæœªåˆå§‹åŒ–ï¼Œç„¡éœ€é‡‹æ”¾")
            return
        
        print("\n" + "="*60)
        print("ğŸ—‘ï¸  é–‹å§‹é‡‹æ”¾æ¨¡å‹è³‡æº...")
        print("="*60)
        
        # è¨˜éŒ„é‡‹æ”¾å‰çš„è¨˜æ†¶é«”ä½¿ç”¨
        if torch.cuda.is_available():
            gpu_mem_before = torch.cuda.memory_allocated() / 1024**3  # GB
            print(f"é‡‹æ”¾å‰ GPU è¨˜æ†¶é«”: {gpu_mem_before:.2f} GB")
        
        # 1ï¸âƒ£ é‡‹æ”¾ GroundingDINO
        print("\n[1/4] é‡‹æ”¾ GroundingDINO...")
        if hasattr(self, 'gd_model') and self.gd_model is not None:
            del self.gd_model
            self.gd_model = None
            print("      âœ“ GroundingDINO å·²é‡‹æ”¾")
        
        # 2ï¸âƒ£ é‡‹æ”¾ SAM
        print("[2/4] é‡‹æ”¾ SAM...")
        if hasattr(self, 'predictor') and self.predictor is not None:
            del self.predictor
            self.predictor = None
            print("      âœ“ SAM å·²é‡‹æ”¾")
        
        # 3ï¸âƒ£ é‡‹æ”¾ CLIP
        print("[3/4] é‡‹æ”¾ CLIP...")
        if hasattr(self, 'clip_model') and self.clip_model is not None:
            del self.clip_model
            self.clip_model = None
        if hasattr(self, 'clip_processor') and self.clip_processor is not None:
            del self.clip_processor
            self.clip_processor = None
        print("      âœ“ CLIP å·²é‡‹æ”¾")
        
        # 4ï¸âƒ£ é‡‹æ”¾æ¡æŸ„ç‰¹å¾µ
        print("[4/4] é‡‹æ”¾æ¡æŸ„ç‰¹å¾µ...")
        if hasattr(self, 'handle_reference_features') and self.handle_reference_features is not None:
            del self.handle_reference_features
        if hasattr(self, 'handle_features') and self.handle_features is not None:
            del self.handle_features
            self.handle_reference_features = None
            print("      âœ“ æ¡æŸ„ç‰¹å¾µå·²é‡‹æ”¾")
        
        # å¼·åˆ¶åƒåœ¾å›æ”¶
        print("\nğŸ”„ åŸ·è¡Œåƒåœ¾å›æ”¶...")
        gc.collect()
        
        # æ¸…ç©º CUDA å¿«å–
        if torch.cuda.is_available():
            print("ğŸ”„ æ¸…ç©º CUDA å¿«å–...")
            torch.cuda.empty_cache()
            torch.cuda.synchronize()  # ç¢ºä¿æ‰€æœ‰ CUDA æ“ä½œå®Œæˆ
            
            gpu_mem_after = torch.cuda.memory_allocated() / 1024**3  # GB
            gpu_cache_after = torch.cuda.memory_reserved() / 1024**3  # GB
            print(f"é‡‹æ”¾å¾Œ GPU è¨˜æ†¶é«”: {gpu_mem_after:.2f} GB")
            print(f"é‡‹æ”¾çš„è¨˜æ†¶é«”: {gpu_mem_before - gpu_mem_after:.2f} GB")
            print(f"å¿«å–è¨˜æ†¶é«”: {gpu_cache_after:.2f} GB")
        
        self._initialized = False
        print("\n" + "="*60)
        print("âœ… è³‡æºé‡‹æ”¾å®Œæˆï¼")
        print("="*60 + "\n")
    
    @classmethod
    def reset_singleton(cls):
        """é‡ç½®å–®ä¾‹å¯¦ä¾‹ï¼ˆç”¨æ–¼å®Œå…¨é‡æ–°åˆå§‹åŒ–ï¼‰"""
        if cls._instance is not None:
            print("\nğŸ”„ é‡ç½®å–®ä¾‹å¯¦ä¾‹...")
            if hasattr(cls._instance, 'release'):
                cls._instance.release()
            cls._instance = None
            print("âœ“ å–®ä¾‹å·²é‡ç½®\n")
    
    def get_memory_usage(self):
        """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            return {
                "device": "GPU",
                "allocated_gb": f"{allocated:.2f}",
                "reserved_gb": f"{reserved:.2f}",
                "device_name": torch.cuda.get_device_name(0)
            }
        else:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            return {
                "device": "CPU",
                "rss_gb": f"{memory_info.rss / 1024**3:.2f}",
                "vms_gb": f"{memory_info.vms / 1024**3:.2f}"
            }

# å…¨å±€æ¨¡å‹å–®ä¾‹
shared_models = SharedModels()
